# Architecture Overview

## ğŸ“ System Architecture

Dá»± Ã¡n BTC Prediction MLOps Ä‘Æ°á»£c thiáº¿t káº¿ theo kiáº¿n trÃºc microservices vá»›i cÃ¡c thÃ nh pháº§n Ä‘á»™c láº­p, dá»… dÃ ng má»Ÿ rá»™ng vÃ  báº£o trÃ¬.

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        External Services                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         Binance API                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Ingestion Layer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Extract    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Transform   â”‚â”€â”€â”€â”€â–¶â”‚     Load     â”‚  â”‚
â”‚  â”‚  (Binance)   â”‚      â”‚  (Features)  â”‚     â”‚ (MinIO/PG)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Storage Layer                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    MinIO     â”‚      â”‚ PostgreSQL   â”‚     â”‚   MinIO      â”‚  â”‚
â”‚  â”‚  (Raw Data)  â”‚      â”‚  (Metadata)  â”‚     â”‚   (Models)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML Training Layer                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Feature Eng.  â”‚â”€â”€â”€â”€â”€â–¶â”‚Model Trainingâ”‚â”€â”€â”€â”€â–¶â”‚   Evaluate   â”‚  â”‚
â”‚  â”‚  (Pipeline)  â”‚      â”‚(Grid Search) â”‚     â”‚(Best Model)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prediction Layer                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Load Model   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Predict    â”‚â”€â”€â”€â”€â–¶â”‚Store Results â”‚  â”‚
â”‚  â”‚ (From MinIO) â”‚      â”‚(BTC Price)   â”‚     â”‚(PostgreSQL)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Orchestration Layer                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Apache Airflow (Scheduler + DAGs)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CI/CD Layer                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Gitea     â”‚â”€â”€â”€â”€â”€â–¶â”‚   Jenkins    â”‚â”€â”€â”€â”€â–¶â”‚Deploy/Test   â”‚  â”‚
â”‚  â”‚(Git Server)  â”‚      â”‚(Build/Test)  â”‚     â”‚(Automation)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Core Components

### 1. Data Ingestion Layer

**Purpose**: Thu tháº­p vÃ  xá»­ lÃ½ dá»¯ liá»‡u Bitcoin tá»« Binance API

**Components**:
- **Extract Module** (`data_pipeline/extract.py`):
  - Káº¿t ná»‘i vá»›i Binance API
  - Thu tháº­p OHLCV data (Open, High, Low, Close, Volume)
  - Há»— trá»£ khoáº£ng thá»i gian tÃ¹y chá»‰nh
  - Xá»­ lÃ½ rate limiting vÃ  retry logic

- **Transform Module** (`data_pipeline/transform.py`):
  - Feature engineering (SMA, VWAP, Bollinger Bands)
  - Data quality checks
  - Data profiling vá»›i ydata_profiling
  - Normalization vÃ  scaling

- **Load Module** (`data_pipeline/load.py`):
  - LÆ°u raw data lÃªn MinIO (partitioned by date)
  - LÆ°u processed data lÃªn MinIO
  - Insert predictions vÃ o PostgreSQL
  - Error handling vÃ  logging

### 2. Storage Layer

**MinIO (S3-Compatible Storage)**:
- **Raw Data Bucket**: `btc-prediction/raw/`
  - Parquet files partitioned by year/month/day
  - Immutable raw data
- **Processed Data Bucket**: `btc-prediction/processed/`
  - Feature-engineered data
  - Ready for model training
- **Model Bucket**: `btc-prediction/models/`
  - Serialized model files (.pkl)
  - Model metadata and versioning

**PostgreSQL**:
- **Airflow Metadata**: DAG runs, task instances, logs
- **Predictions Table**: LÆ°u trá»¯ káº¿t quáº£ dá»± Ä‘oÃ¡n
- **Model Performance**: Metrics vÃ  evaluation results

### 3. ML Training Layer

**Components**:

- **Model Training** (`btc_prediction/train_and_predict.py`):
  - Multiple model support:
    - Ridge Regression
    - Lasso Regression
    - ElasticNet
    - Random Forest
    - Gradient Boosting
  - Grid Search for hyperparameter tuning
  - Cross-validation
  - Model serialization

- **Model Evaluation**:
  - MSE (Mean Squared Error)
  - MAE (Mean Absolute Error)
  - RÂ² Score
  - Model comparison vÃ  selection

### 4. Prediction Layer

**Components**:

- **Model Loading** (`btc_prediction/train_and_predict.py`):
  - Load best model tá»« MinIO
  - Load scaler vÃ  preprocessing artifacts

- **Prediction Service**:
  - Real-time predictions
  - Batch predictions
  - Feature preprocessing
  - Result formatting

- **Result Storage**:
  - Save predictions to PostgreSQL
  - Timestamp vÃ  metadata tracking
  - Version control

### 5. Orchestration Layer

**Apache Airflow**:

- **DAG Definition** (`dags/etl_and_predict_btc.py`):
  - Schedule: Hourly (`0 * * * *`)
  - Tasks:
    1. `run_etl_pipeline`: Extract, Transform, Load
    2. `run_train_model`: Train vÃ  predict
  - Dependencies: ETL â†’ Training

- **Features**:
  - Task retry mechanism
  - Email notifications on failure
  - Task logging vÃ  monitoring
  - Backfill support

### 6. CI/CD Layer

**Jenkins**:
- Automated testing (pytest)
- Code quality checks (ruff, pylint)
- Docker image building
- Deployment automation

**Gitea**:
- Git repository hosting
- Webhook integration vá»›i Jenkins
- Pull request workflows

## ğŸ”„ Data Flow

### ETL Pipeline Flow

```
1. Binance API Call
   â”œâ”€ Get OHLCV data for time range
   â””â”€ Handle pagination

2. Data Extraction
   â”œâ”€ Fetch hourly candles
   â”œâ”€ Validate data completeness
   â””â”€ Save to MinIO (raw)

3. Data Transformation
   â”œâ”€ Calculate technical indicators
   â”œâ”€ Generate features
   â”œâ”€ Data quality checks
   â””â”€ Save to MinIO (processed)

4. Data Loading
   â”œâ”€ Load to PostgreSQL (if needed)
   â””â”€ Update metadata tables
```

### ML Training Flow

```
1. Data Loading
   â”œâ”€ Read processed data from MinIO
   â””â”€ Filter by date range

2. Feature Preparation
   â”œâ”€ Select feature columns
   â”œâ”€ Split train/test
   â””â”€ Scale features (StandardScaler)

3. Model Training
   â”œâ”€ For each model candidate:
   â”‚   â”œâ”€ Grid search hyperparameters
   â”‚   â”œâ”€ Train vá»›i best params
   â”‚   â””â”€ Evaluate performance
   â””â”€ Select best model

4. Model Saving
   â”œâ”€ Serialize model + scaler
   â”œâ”€ Save to MinIO
   â””â”€ Log metrics to database

5. Prediction
   â”œâ”€ Load latest features
   â”œâ”€ Predict next hour price
   â””â”€ Save to PostgreSQL
```

## ğŸ” Security Architecture

### Authentication & Authorization

- **MinIO**: Access key + Secret key authentication
- **PostgreSQL**: Username/password authentication
- **Airflow**: Web authentication (admin/admin)
- **Jenkins**: User-based authentication
- **Gitea**: User accounts with SSH keys

### Network Security

- All services run in Docker network
- Exposed ports:
  - Airflow: 8080
  - Jenkins: 8081
  - Gitea: 3001
  - MinIO Console: 9001
  - PostgreSQL: 5432 (internal)

### Data Security

- Secrets managed via environment variables
- No hardcoded credentials
- API keys stored in `.env` file (not in git)
- TLS/SSL for external API calls

## ğŸ“Š Monitoring & Logging

### Logging Strategy

- **Application Logs**: Using `loguru` library
  - Structured logging
  - Log levels: DEBUG, INFO, WARNING, ERROR
  - Log rotation vÃ  archival

- **Airflow Logs**: 
  - Task execution logs
  - Scheduler logs
  - Stored in `/opt/airflow/logs/`

- **Docker Logs**:
  - `docker-compose logs <service>`
  - Persisted trong container volumes

### Monitoring Points

- **Data Quality**: Profiling reports
- **Model Performance**: MSE, MAE, RÂ² metrics
- **Pipeline Health**: Airflow task success rate
- **Resource Usage**: Docker container stats
- **API Health**: Binance API response time

## ğŸš€ Scalability Considerations

### Horizontal Scaling

- **Airflow**: Add more worker nodes
- **MinIO**: Distributed mode vá»›i multiple nodes
- **PostgreSQL**: Read replicas for queries

### Vertical Scaling

- Increase Docker container resources
- Optimize model training parameters
- Database query optimization

### Performance Optimization

- Batch processing for large datasets
- Caching frequently accessed data
- Parallel model training
- Incremental data loading

## ğŸ”§ Configuration Management

### Environment Variables

All configurations stored in `.env`:
- Database connections
- API credentials
- Service endpoints
- Feature flags

## ğŸ“ˆ Future Architecture Enhancements

### Planned Improvements

1. **Model Serving**:
   - FastAPI/Flask REST API for predictions
   - Model serving vá»›i MLflow
   - A/B testing infrastructure

2. **Real-time Processing**:
   - Kafka/Redis for streaming data
   - Real-time feature computation
   - Online learning capabilities

3. **Advanced Monitoring**:
   - Prometheus + Grafana dashboards
   - Model drift detection
   - Data drift monitoring
   - Alerting system

4. **Enhanced Security**:
   - HashiCorp Vault for secrets
   - RBAC (Role-Based Access Control)
   - Audit logging
   - Encryption at rest

5. **Scalability**:
   - Kubernetes deployment
   - Auto-scaling policies
   - Load balancing
   - Multi-region support

## ğŸ“š Related Documentation

- [Data Pipeline Details](data-pipeline.md)
- [ML Pipeline Details](ml-pipeline.md)
- [Deployment Guide](../deployment/docker.md)
- [API Reference](../api/data-pipeline.md)
